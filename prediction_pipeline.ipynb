{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/genomic-ml/da2343/cs685/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/projects/genomic-ml/da2343/cs685/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DiatomDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path: Path to the CSV file with annotations\n",
    "            img_dir: Directory with all the images\n",
    "            transform: Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Extract Cocconeis counts and normalize them\n",
    "        self.counts = self.data['Cocconeis'].values\n",
    "        self.scaler = StandardScaler()\n",
    "        self.normalized_counts = self.scaler.fit_transform(self.counts.reshape(-1, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path and load image\n",
    "        img_name = self.data.iloc[idx]['micrograph ID']\n",
    "        img_path = self.img_dir / f\"{img_name}.tif\"\n",
    "        image = tifffile.imread(str(img_path))\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        image = self.preprocess_image(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get normalized count\n",
    "        count = self.normalized_counts[idx]\n",
    "        \n",
    "        return image, torch.tensor(count, dtype=torch.float32)\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        \"\"\"Enhanced preprocessing pipeline.\"\"\"\n",
    "        # Convert to RGB if needed\n",
    "        if len(image.shape) == 3:\n",
    "            img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if image.shape[-1] == 3 else image\n",
    "        else:\n",
    "            img_rgb = np.stack([image] * 3, axis=-1)\n",
    "        \n",
    "        # Resize\n",
    "        resized = cv2.resize(img_rgb, (512, 512), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Enhance contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        enhanced = np.zeros_like(resized, dtype=np.float32)\n",
    "        for i in range(3):\n",
    "            enhanced[:,:,i] = clahe.apply((resized[:,:,i]).astype(np.uint8))\n",
    "        \n",
    "        # Normalize\n",
    "        normalized = (enhanced.astype(float) - 127.5) / 127.5\n",
    "        return normalized\n",
    "\n",
    "class DiatomCountPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiatomCountPredictor, self).__init__()\n",
    "        # Use EfficientNet-B0 as backbone\n",
    "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "        \n",
    "        # Modify the classifier head\n",
    "        num_ftrs = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "        # Add attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(1280, 1, kernel_size=1),  # EfficientNet-B0 feature size\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get features from backbone (before classifier)\n",
    "        features = self.backbone.features(x)\n",
    "        \n",
    "        # Apply attention\n",
    "        attention_weights = self.attention(features)\n",
    "        features = features * attention_weights\n",
    "        \n",
    "        # Continue with classifier\n",
    "        x = self.backbone.avgpool(features)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.backbone.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        predictions = []\n",
    "        actual = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                predictions.extend(outputs.cpu().numpy())\n",
    "                actual.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate percentage error\n",
    "        pred_array = np.array(predictions)\n",
    "        actual_array = np.array(actual)\n",
    "        percentage_error = np.mean(np.abs((pred_array - actual_array) / actual_array)) * 100\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Training Loss: {train_loss/len(train_loader):.4f}')\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}')\n",
    "        print(f'Mean Percentage Error: {percentage_error:.2f}%')\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Data augmentation transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(degrees=0, scale=(0.8, 1.2)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiatomDataset(\n",
    "    csv_path='Kraken_2023_measurements.csv',\n",
    "    img_dir='/projects/genomic-ml/da2343/diatom/train',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "# Create k-fold splits\n",
    "kfold = KFold(n_splits=5, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
